{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengjiyang/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgzDIJwEovhk",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "YV59Ziqcovhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "Xzf_Wx1Hovhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "ToYZ3ZS8ovh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f6a1a15-720f-4559-9b8c-b5569098290e"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "      <td>2777</td>\n",
              "      <td>7738</td>\n",
              "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>7739</td>\n",
              "      <td>11840</td>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>11841</td>\n",
              "      <td>14631</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>14632</td>\n",
              "      <td>17832</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>17833</td>\n",
              "      <td>27806</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0            ALL’S WELL THAT ENDS WELL  ...  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "1  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...\n",
              "2                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...\n",
              "3                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "4            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC1BHBadu7HP",
        "colab_type": "text"
      },
      "source": [
        "###Understanding the Lecture\n",
        "\n",
        "Before begining the actual assignment, for my understanding, I have replicated\n",
        "the lesson code with the Shakespearean content. Note that I have also created explanations for some of the numpy functions used in local functions from JC's lesson code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4gPJY4H25ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding the data\n",
        "\n",
        "text = \"\".join(df_toc.text.values)\n",
        "\n",
        "# Unique characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup tables\n",
        "# I had no idea that \"dict comprehension\" was a thing\n",
        "char_int = {c:i for i, c in enumerate(chars)}\n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbkgXaOf6CHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac0ef29-6a71-4173-96c3-4ca366a83a0e"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq6F68wa6LtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c940ecdf-2d2d-499a-eb64-089257659aed"
      },
      "source": [
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "\n",
        "  sequences.append(encoded[i : i + maxlen])\n",
        "  next_char.append(encoded[i + maxlen])\n",
        "\n",
        "# Sanity Check\n",
        "(len(sequences), len(next_char))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1127153, 1127153)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwOViUak6_yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92857c8b-e8e3-4294-c8df-8b71eae9d77d"
      },
      "source": [
        "# Creating an X and y for our LSTM model to use.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# This will tell the model whether a given character is found in\n",
        "# a given place by reading out that character's index value from \n",
        "# the dictionary above and outputting an array with True or False\n",
        "# values telling us whether that character exist in a given position\n",
        "# in the text.\n",
        "X = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "  for t, char in enumerate(sequence):\n",
        "    X[i, t, char] = 1\n",
        "\n",
        "  y[i, next_char[i]] = 1\n",
        "\n",
        "(X.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1127153, 40, 106), (1127153, 106))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3axQWqbgFDgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Building the text generation model\n",
        "\n",
        "model = Sequential([\n",
        "                    LSTM(128, input_shape=(maxlen, len(chars))),\n",
        "                    Dense(len(chars), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcF6gy2npQB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "  \"\"\"\n",
        "  Samples an index from a probability array.\n",
        "  \"\"\"\n",
        "  preds = np.asarray(preds).astype(\"float64\")\n",
        "  preds = np.log(preds) / 1\n",
        "  # np.exp() invokes Euler's constant to the power of the log of the prediction(s).\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn_QaWXry19M",
        "colab_type": "text"
      },
      "source": [
        "Understanding np.random.multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkxyv6yoy6w9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ee268b7-5759-4638-e237-f16aa3d56e32"
      },
      "source": [
        "# The first argument n=8 determines, the range of values, in this case 0 to 8/\n",
        "# The second argument pvals=[0.1, 0.22, 0.333, 0.4444] is a list of probability\n",
        "# values, which sum up to 1.\n",
        "# The third argument determines the vertical size of the array, as can be seen\n",
        "# in the third itteration below.\n",
        "multinomial = np.random.multinomial(8, [0.1, 0.22, 0.333, 0.4444], 2)\n",
        "multinomial"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 2, 4],\n",
              "       [2, 3, 3, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfyjPEaezF1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d01d7d7f-fdfb-424b-f3c8-ba85d4d99f33"
      },
      "source": [
        "multinomial = np.random.multinomial(12, [0.1, 0.22, 0.333, 0.4444], 3)\n",
        "multinomial"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 5, 4, 1],\n",
              "       [0, 6, 1, 5],\n",
              "       [0, 6, 4, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8amMD0yzKkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "475e9519-c19b-424e-8a68-e7da5631b44f"
      },
      "source": [
        "# Here we have passed n=1 and size=1 into the multinomial in order to reflect\n",
        "# the use of np.random.multinomial in the sample function. Essentially,\n",
        "# The multinomial array creates binary values 0 or 1 from predictions it is fed.\n",
        "multinomial = np.random.multinomial(1, [0.1, 0.22, 0.333, 0.4444], 1)\n",
        "multinomial"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KdRjscn4YaH",
        "colab_type": "text"
      },
      "source": [
        "Understanding np.argmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UdzekZF4a7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "205bfd94-b03a-445f-e067-14dde650bd6b"
      },
      "source": [
        "# np.argmax returns index positions of the max values for each row or column of\n",
        "# an array.\n",
        "# In order to demonstrate np.argmax, we must also understand np.arange.\n",
        "\n",
        "# Here np.arange is used. np.arange creates a discrete counter of values staring\n",
        "# at zero and increasing by one until the number of itterations, in this case 6,\n",
        "# is reached.\n",
        "a = np.arange(6)\n",
        "print(\"a\")\n",
        "print(a)\n",
        "\n",
        "print(\"\\nb\")\n",
        "b = np.arange(6) + 1\n",
        "print(b)\n",
        "\n",
        "print(\"\\nc\")\n",
        "c = np.arange(6) + 10\n",
        "print(c)\n",
        "\n",
        "print(\"\\nd\")\n",
        "# Here .reshape takes the existing one dimensional array and creates a matrix\n",
        "# with the dimensions inserted into it.\n",
        "d = np.arange(6).reshape(2,3) + 10\n",
        "print(d)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "[0 1 2 3 4 5]\n",
            "\n",
            "b\n",
            "[1 2 3 4 5 6]\n",
            "\n",
            "c\n",
            "[10 11 12 13 14 15]\n",
            "\n",
            "d\n",
            "[[10 11 12]\n",
            " [13 14 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gymxAV1j-fXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abf90bea-123a-4811-9e0b-2eaa9b113456"
      },
      "source": [
        "# np.argmax itself\n",
        "\n",
        "# for rows\n",
        "\n",
        "# Since NumPy arrays are zero-indexed, the value 2 was returned twice for each\n",
        "# row, indicating the third column\n",
        "max_rows = np.argmax(d, axis=1)\n",
        "max_rows"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7eKH_Ms_WN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e00f83b-bae0-4ac9-adc8-9fc34cf70cf9"
      },
      "source": [
        "# for columns\n",
        "max_columns = np.argmax(d, axis=0)\n",
        "max_columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw2d-qUZ_uBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import sys\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "  \"\"\"\n",
        "  Function invoked at the end of each epoch passed by the neural network.\n",
        "  Prints out the text generated by the model.\n",
        "  \"\"\"\n",
        "\n",
        "  print()\n",
        "  # Here the %d in the formatted string indicates\n",
        "  # that each new epoch is counted as a discrete\n",
        "  # integer.\n",
        "  print('----- Generating text after Epoch %d:' % epoch + 1)\n",
        "\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "\n",
        "  generated = ''\n",
        "\n",
        "  sentence = text[start_index : start_index + maxlen]\n",
        "  generated += sentence\n",
        "\n",
        "  print('----- Generating with seed: \"' + sentence + '\"')\n",
        "  sys.stdout.write(generated)\n",
        "\n",
        "  for i in range(400):\n",
        "    X_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      X_pred[0, t, char_int[char]] = 1\n",
        "\n",
        "    preds = model.predict(X_pred, verbose=0)[0]\n",
        "    next_index = sample(preds)\n",
        "    next_char = int_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "  print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4fCsc3ODsGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d5b5064-3dc8-4ae0-f280-1df384c8f521"
      },
      "source": [
        "# Understanding string formatting\n",
        "\n",
        "data = (\"John\", \"Doe\", 53.44)\n",
        "format_string = \"Hello\"\n",
        "\n",
        "print(\"%s, %s %s.\\nYour current balance is $%.2f.\" % (format_string, data[0], data[1], data[2]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, John Doe.\n",
            "Your current balance is $53.44.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL2tbaN0DvS9",
        "colab_type": "text"
      },
      "source": [
        "Eventually, I'll need to go back and understand how sys works on a deeper level, but for now, we'll just roll with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ey1Lt_EAdM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "640ba4f9-edcd-4f58-f80f-8f8075be8024"
      },
      "source": [
        "# Fitting the model and generating our ridiculous results:\n",
        "\n",
        "model.fit(X,\n",
        "          y,\n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "35216/35224 [============================>.] - ETA: 0s - loss: 1.6222\n",
            "----- Generating text after Epoch 0:\n",
            "----- Generating with seed: \"bewray whose brat thou art,\n",
            "    Had nat\"\n",
            "bewray whose brat thou art,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  CLENDIA. Yes, that had have hearss crown of any, and thy searing permalls d\n",
            "35224/35224 [==============================] - 156s 4ms/step - loss: 1.6222\n",
            "Epoch 2/3\n",
            "35221/35224 [============================>.] - ETA: 0s - loss: 1.5285\n",
            "----- Generating text after Epoch 1:\n",
            "----- Generating with seed: \";\n",
            "We are one anothers wife, ever begett\"\n",
            ";\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fr\n",
            "35224/35224 [==============================] - 156s 4ms/step - loss: 1.5285\n",
            "Epoch 3/3\n",
            "35222/35224 [============================>.] - ETA: 0s - loss: 1.4782\n",
            "----- Generating text after Epoch 2:\n",
            "----- Generating with seed: \"Recoil upon me: in himself too mighty,\n",
            "\"\n",
            "Recoil upon me: in himself too mighty,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I loves into the hows, he not forcess: the \n",
            "35224/35224 [==============================] - 155s 4ms/step - loss: 1.4782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f14ab6b3320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}